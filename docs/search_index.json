[["index.html", "A Reference Manual for the Biostatistics GRA Towards accessible, rigorous, and reproducible results Chapter 1 Motivation &amp; TLDR 1.1 Context 1.2 What this book assumes 1.3 Acronymns 1.4 Working with the garage door open 1.5 Dedication", " A Reference Manual for the Biostatistics GRA Towards accessible, rigorous, and reproducible results T. K. Peter 2024-09-06 Chapter 1 Motivation &amp; TLDR The purpose of this reference manual is to help early-career trainees in biostatistics to have a place to begin. This work is a reference manual, which means most of its contents are not new. Rather, the novelty in what I am providing here is in its form and organization. During the last couple of years of my PhD program, I set out to gather resources together to help the newer GRAs on my team, with the goal of helping them by sharing the links, lectures, and tips that have helped me the most. What I am publishing here is the result of that work. Although this reference manual is intended to serve graduate students and early career professionals in biostatistics, some of those working in the fields of statistics, data science, and bioinformatics may also find this manual relevant to their work. The objective of this manual is twofold: to provide starting points from which to address common questions of practice, and to summarize the references and tools which I have found most helpful in my journey through gradate school and my early years as a biostatistician. Overarching these two goals is a desire to make a contribution toward training biostatisticians whose work is professional, accessible, rigorous, and reproducible. If even one other person is encouraged and sharpened by this work, my goal will be accomplished. 1.1 Context The meta-question behind this short book is ‘where to begin?’. I started graduate school in August of 2019, coming straight from an undergrad math program 1 to a doctoral program in biostatistics. In the same week that I started classes, I started my work as a graduate research assistant (GRA) in the Division of Biostatistics and Computational Biology at the University of Iowa College of Dentistry. It was a steep learning curve. Now heading into my 6th year as a Ph.D. student, I began compiling some notes/tips to share with the other GRA’s who joined our team after me. Those notes have become this reference manual. When you are starting off as a GRA in a new field, you need to know what to Google. Yes, a significant component of graduate level study is learning how to learn. You need to struggle with hard concepts and new ideas – the learning is truly in the struggle. At the same time, however, you need to know where to start. This creates a tension: new GRAs need to engage in independent study work, but they also need resources that teach them some first principles to guide their search. If you don’t know what your searching for, you won’t know if you’ve found it. Moreover, if you are a novice who thinks you know what you are searching for, you could easily come across bad advice (by ‘bad’, I mean that which leads to suboptimal outcomes with respect to rigor and reproducibility). With this tension in mind, the goal of this reference manual is to (1) outline some of the main ideas that you will need to be successful, and (2) to provide you with some vocabulary to help you as you learn independently. Many of the chapters here outline some general concepts and then provide links to further reading. 1.2 What this book assumes This is a reference manual, not a textbook. As such, my philosophy in writing this is to summarize the most helpful things I have learned in a way that is conducive to quick review. The chapters that are titled after broad areas of research (e.g., ‘survival analysis’) contain more links than new content. I assume throughout this writing that the readers are either familiar with foundational statistical concepts or are currently in courses that are teaching those concepts. 1.3 Acronymns Throughout this work, I use the following acronyms: GRA: Graduate research assistant PI: Primary investigator CC: Carbon copy (as in an email) UI: University of Iowa HPC: High performance computing SAS: Statistical Analysis System software GWAS: Genome-wide association study 1.4 Working with the garage door open This manual is not comprehensive, and it is a work in progress. I am writing this as I work my way through my own program, making notes as I go. This is in the spirit of working with the garage door open, an approach to learning that really resonates with me. If you think of a reference that you’d like to see included, open a GitHub issue or make a pull request to let me know. 1.5 Dedication This work is dedicated in memory of my father, Bill Peter (1955-2022). I got a B.S. in math from Wheaton College, IL↩︎ "],["organization.html", "Chapter 2 Getting organized: The first 3 days of a new RA job 2.1 File structure 2.2 Emails 2.3 Project notes and README files", " Chapter 2 Getting organized: The first 3 days of a new RA job The first step in starting out as a research assistant is establishing habits of organization. You will be more productive and produce higher quality work – work that is reproducible and rigorous – if you begin by establishing an organizational system. I will outline here both general principles and some specific strategies that have proven helpful for my work. These points are organized according to the three major components to your work system that should be established within your first few days on the job: File structure Emails Notes and README files 2.1 File structure ‘File structure’ refers to the system for categorizing your code, notes, reports, and figures for each project. Here are some general principles: One master folder per project the ‘master folder’ structure translates well to starting GitHub repositories [CROSS REF]. Subfolders for each file type keeping subfolders by file type will help you find what you are looking for. Also, doing it this way will let you script your work from the command line with ease – for example, you can apply a function or use an executable file to work with all the items in a given folder. Names that are readable for both humans and machines use names that can be easily ordered by a computer; again, this helps with writing scripts. avoid using white spaces, as this is a hassle for machines to read. Choose to work with either ‘CamelCase’ or ‘snake_case’, and be consistent. use specific keywords in file names: ‘summary_stats_report’ is better than ‘report1’ move old versions into a subfolder called ‘outdated’2 You want to avoid having folder with files with ambiguous names, e.g., “final_version”, “final_final_version”, “my_version3”, etc. it’s worth saying again: choose a convention and be consistent one more time for the folks in the back: choose a convention and be consistent. for a brief (and entertaining) tutorial on naming things, checkout Jenny Bryan’s YouTube video. Example Here is a step-by-step example of how I use a file structure to organize myself at the start of a new project (if you’d prefer, skip to the video). Suppose I am contacted by Collaborator A for support on a study of a new endodontic treatment… I begin by creating a new folder with a name that fits my established convention. For my new project, I would create a folder TKP23-A-Endo. My folders are stored in a shared drive to which other biostatistician have access, so I begin my folder names with my initials (TKP). the ‘23’ tells me that the project started in 2023. The ‘A’ and ‘Endo’ keywords tell me who is the PI/what project it is (this is helpful since it is not uncommon for me to have multiple projects from the same lab). The first file I add to my new TKP23-A-Endo folder is a README file. This includes notes from the initial meeting/first email from Collaborator A. I open RStudio and go to File &gt; New Project. I follow the prompts to create a new project, and the directory (a.k.a the folder) in which this project will live is my new TKP23-A-Endo folder. Using an R project is an example of a broader principle of project-oriented workflow. I go to my TKP23-A-Endo folder (which now has two things in it: a .Rproj file and a README file), and I make 4 subfolders: data, scripts, reference, and reports. These are the building blocks of my projects. I will get data from Collaborator A, and it will go in the data folder. Nothing else will go in the data folder, and I will never change any of the original data files. In some cases (e.g., projects where you need to make subsets of data), I create a subfolder of ‘data/’ called ‘original/’, just to make sure I keep track of which files should never be edited. scripts will be the place where I put all of the code I use for data cleaning and analysis. reference is where I will put things Collaborator A shares with me that help me understand the research question – this could be articles in endodontics that provide an explanation of the terminology, or a PowerPoint that explains how the data are collected. I would also keep a copy of the IRB documentation in this reference folder. reports is where I will keep my final .Rmd file for writing the report which I will share with Collaborator A. From here, I begin writing scripts. As the project moves along, I may find that I need other subfolders. For instance, a graphics subfolder would be useful if I am making a ton of plots for a project. If I am writing a manuscript and there’s quite a bit of back-and-forth with reviewers, I would use a submission subfolder that contains all my point-to-point responses (CROSS REF) for reviewers. 2.1.1 Please use relative file paths Computers work with files by having a ‘pointer’ at a specific folder, called a directory. Your computer probably has many directories on it – for example, ‘Desktop’ and ‘Downloads’ are both directories you have by default in most operating systems. When you are doing project-based quantitative work, your scripts (the files with the code in them) will need to ‘point’ to data that is probably in another place. Instead of copying data into multiple folders, or using functions like setwd(), use relative filepaths. This can be accomplished using the .. symbol to reference a parent directory. Here is a short video on how I use relative file paths. For those coding in R: when you are writing code that constructs file paths, use the file.path() function and not paste() or paste0(). The file.path() function ensures that file paths can be read on different kinds of operating systems (Windows and MacOS, etc.). 2.2 Emails Email management is of paramount importance for collaboration. Emails serve 2 purposes: Providing a paper trail to document important exchanges of information Facilitating conversations that can happen in an asynchronous way I have found the Inbox Zero method for email management to be a helpful place to begin. This method breaks down emails in to 4 categories: delete, delegate, defer, and do. Practically speaking, I have folders named for each person with whom I correspond. When I receive a new email that needs an answer, this goes in a ‘needs follow up’ folder. After following up, I move the conversation to the folder with the appropriate name (with group conversations categorized by the PI). I do not recommend using emails to exchange versions of important files. Several tools exist to facilitate collaboration in a more efficient way - Microsoft offers ‘OneDrive’, Google offers ‘GoogleDrive’, and of course, there’s GitHub. In addition, most organizations have a some kind of shared drive/shared repository. As often as possible, use shared resources for file sharing as opposed to emailing different versions. 2.3 Project notes and README files You have to keep track of what you are learning. In addition, you need to keep a log of what you have done so that other collaborators/future RAs can look back and figure out what you did. Let’s call these two tasks internal documentation (keeping track of your project-specific work) and external documentation (the project-specific notes you want to leave for others). I recommend writing project notes for internal documentation, and README files for external documentation. 2.3.1 Project notes Each project is a process that unfolds over time. As you learn over the course of a project, you’ll need some kind of time-organized system for keeping track of your thoughts and action items. Using Google Drive, I have created a system of weekly project notes to serve this purpose. The setup looks like this: Weekly notes template Each week (typically on Monday morning), I create a new Google doc file named YYYY_MM_DD1-DD2_notes (YYYY = year, MM = month, DD1-2 = dates of Monday &amp; Friday). On the first page, I set goals for the week. I check off things that are completed by marking them as done. Colored fonts help me stay organized, especially in seasons where I have several collaborative projects going on concomitantly. I often use blue text to show things that are done, and red text to show deadlines. At the left panel, you can see that each subsequent page of my document is given a subheading link with the collaborator’s name. To navigate to my notes for each collaborator, I can use these subheading links to quickly find what I am looking for. If I click on Collaborator A, I would see this page: Detail notes for a specific collaborator My notes for each project are typically sorted into times/deadlines, notes, and action items. Whereas my weekly goals are different each week, I probably won’t address all the action items for each project in a given week. The notes on this “Collaborator A” page may are updated only as often I am working on this project/in contact with the collaborator. At the start of the next week, I begin my copying the notes from the previous week (the whole file) and then updating the weekly goals. This is an iterative process, where the ‘current’ value becomes the ‘old’ value in the next iteration. This system of file keeping has allowed me to focus my goals for each week, to measure the progress I am making, and to reference projects that resurface after a long break (which is typical). No one else has access to these notes except me, and I write them in ‘shorthand’ (using acronyms, etc.) knowing that these notes are just for my personal reference. Notice that these notes are both (1) linear (chronological) and (2) project-specific. These features differentiate project notes from the kinds of notes one would need for building a personal knowledge base. Personally, I have found it helpful to keep these two types of notes distinct. My project notes have lots of deadlines, dates, and to-do items – I don’t want these things to get mixed up into my personal knowledge base notes. 2.3.2 README files Each project on which I collaborate has a README file, which has the details that a future analyst would need to jump into a project mid-story. Typically, my README files contain: The names of the PI/collaborators The objective/scientific aim of the project The definitions of any project-specific acronyms Any notes on data analysis decisions (i.e., dichotomizing a continuous variable, etc.). Often, these notes are lines from an important email that I copy &amp; paste into the README. This keeps a coherent record of the decision points in a project timeline. For a deeper dive on writing README files, check out this tutorial article. or, in many cases (esp. for scripts) use version control software like Git. More on that in chapter 5.↩︎ "],["taking-notes.html", "Chapter 3 Taking Notes 3.1 The Zettlekasten system 3.2 How to connect your notes", " Chapter 3 Taking Notes One of the most important aspects of studying at the graduate level is taking notes so as to build a knowledge base. Unlike taking notes in other contexts (e.g., most undergrad programs), the goal for a graduate student/GRA is not to keep a linear track of what you’ve learned over a finite period of time. In undergraduate classes, you probably take notes per lecture, per week, with the objective being a final at the end. You probably seldom (if ever) look back to the notes for any particular class once the semester is over. But in graduate school, note taking has an altogether different goal. Instead of tracking what you are learning in a linear way for a finite time, you are building up what you are learning into a knowledge base to be referenced for the rest of your life. So, I highly recommend that you take notes in a way that helps you connect concepts across coursework and research work. During my 3rd year of grad school, my PhD advisor shared some of his note-taking strategies with me. These strategies transformed the way I learn. Here are some of the ideas that led to that transformation. 3.1 The Zettlekasten system One non-linear note taking approach is the Zettelkasten method. The Writing Cooperative has an article that describes the Zettlekasten system of taking notes. The Zettelkasten method allows you to connect your notes to one another, so that you end up with a web of ideas. This web is similar to the way Wikipedia is set up, with pages linked to other pages. Other variants of this kind of note taking include digital gardening and Evergreen notes. 3.2 How to connect your notes So, this raises the question: where do you start in building up a knowledge base like this? I use the free app called Obsidian. Obsidian allows you to store all your notes in Markdown files on your local machine. There are other apps out there, like Roam. Just keep in mind that Roam does not have a free version (as of the time of this writing). Some people who use this kind of note-taking system have made their notes publicly available. I have learned much from studying these individuals’ notes: Andy Matuschak Maggie Appleton Bryan Jenks I use Obsidian for all of the conceptual notes I take (‘conceptual’ meaning notes that are not reminders/to-do lists). "],["data-management.html", "Chapter 4 Data management 4.1 U. Iowa data sharing policy", " Chapter 4 Data management Closely related to organization is data management. Many graduate research assistants have data management responsibilities in addition to data analysis. Oracle defines data management as the “…practice of collecting, keeping, and using data securely, efficiently, and cost-effectively.” Based on these notes from the University of Mass., here are the general components of data management: Write a data management plan Specify a explicit set of operating procedures Create a data dictionary Determine a data storage location Develop an analysis plan Archive all of your procedures I expand on each of these items below: 4.0.1 Write a data management plan As soon as you receive a new project, you should establish your organization system (refer back to 2). After this, your next step should be to spend some time contemplating a data management plan. This plan should describe how you will keep track of all of the data so that you can explain each step of your analysis process. If collected data comes to you (especially if it comes via an Excel spreadsheet), you should immediately make a copy of this data. You should never edit the original data you receive - do not do any data cleaning or re-formatting. Instead, do all of your work on the copy, so that you can always refer back to the original data. If you are planning a study with yet-to-be- collected data, spend some time thinking about how the data will get to you. Will the data come from electronic records? If so, save the SQL query/other code used to extract the records. Will the data come from a chart review (e.g., a doctor will manually collect data from patient records)? If so, I recommend making a template for the doctor (or whoever is doing the chart review) to fill in. Think about each person who will interact with the data, and have a flow-chart in your mind that traces exactly how this data will come to you. This will help you when you write the “Methods” section of your paper/poster, and will keep you from making mistakes in your analysis downstream. 4.0.2 Specify a explicit set of operating procedures If you are in a situation where multiple people will handle the data (as in the chart review scenario), you should go beyond ‘having a flow chart in your mind’ – in cases like these, write down who will do what with the data at each step of data collection. Send this written document to everyone on the team, and make sure everyone agrees/is on the same page. If you are in the chart review scenario, instruct the person doing chart review on how to collect data that is in a consistent form. Remember that the computer will recognize these responses as four different values: “Yes”, “yes”, “y”, ✅. 4.0.3 Create a data dictionary Create a spreadsheet with all the variables in the study listed in one column, and their definitions listed in the next column. As you write your scripts for analysis, you may even want to add a third column that lists the name you used in the script for that variable. The US Dept. of Agriculture offers some best practices on organizing a data dictionary. 4.0.4 Determine a data storage location Where you keep your data matters. This is of particular importance when working with data protected by HIPPA (e.g., health records data). As a general principle, don’t store data on your personal computer. Store it either online (e.g., a secure OneDrive folder, a GoogleDrive folder, an AWS location) or in an external drive (e.g., a company or university-owned secure shared drive). 4.0.5 Develop an analysis plan At the outset of a project, outline the data analysis tools you think you will use based on the kind of data you expect to receive. Begin with the end in mind. Ask your collaborators these questions: What is your research question? What kind of interpretations/generalizations you want to be able to make at the end of the project? 4.0.6 Archive all of your procedures Document what you have done for data cleaning and analysis. This documentation can include: Well-organized, well-commented code (well-commented does not necessarily mean more comments; in fact comments should not explain what the code is doing). Stick to your file structure, using informative file names. Save a copy of every file you send out for others to read. Even as you update versions of a report, save one copy of each version you have shared. 4.1 U. Iowa data sharing policy This document has the University of Iowa official documentation on data security guidance. I recommend any U. Iowa GRA to become very familiar with this document; the principles may also be helpful for those at other institutions. "],["cultivating-professionalism.html", "Chapter 5 Cultivating professionalism 5.1 Communication 5.2 Handling disagreement 5.3 Maintaining a CV 5.4 Responding to reviewers", " Chapter 5 Cultivating professionalism This chapter covers several aspects of professionalism that arise in the context of collaborative research, including: Communication Handling disagreement Maintaining a CV Responding to reviewers during the publication process Each of these sections is written to be independent of the others, so skip around to what you need. 5.1 Communication 5.1.1 Speaking in the affirmative I have learned that collaboration benefits from speaking in the affirmative tense – that is, speaking from the perspective of what you can do, will do, do know/are learning, and are working on. I’ve noticed that the pervasive mindset among graduate students is to complain, a habit which manifests itself in speaking in terms of what one can’t do, won’t do, don’t know, don’t have time for, etc. Change that narrative. You are not a victim. Moreover, you will be more pleasant to work with if you are positive. Whenever you are communicating with a collaborator (or PI, for that matter), frame your questions and comments in the affirmative. If you don’t know the answer, describe what you will do to work with them towards their goal instead of enumerating the challenges in the way. 5.1.2 Responding to emails I’ve give these in bullets: Respond to all work-related emails in 1-2 business days. If you are out of office, turn on automatic replies. Start your emails with a greeting, and end with an appropriate closing. Use spell check. If you are emailing a student/resident, always CC their advisor/mentor/PI. If you are asking a series of questions, use bullet points – this makes your question easier to read. If you are responding to a series of questions, copy the text from the email with the questions and write your responses directly below, using a highlight or text color to make your answer stand out. This anchors your responses to the question, keeping the conversation in context. If you are meeting with a group for the first time, have a conversation (either in-person or virtually) as an entire group. In my experience, collaborative projects that take place entirely via email exchange are prone to lapses in communication. 5.2 Handling disagreement Here are some tricky situations that may arise when working in a GRA position, along with some suggestions on how to handle them. 5.2.1 The data is not organized in a way that is conducive to analysis If you’ve received data from folks with whom you did not consult before data collection, you may find that the data are ‘messy’ - maybe there are lots of notes in one column, or the data you want is in the column names, or the values within columns are not consistent. There are several resources to help you with processing data in R and/or cleaning data in R. The packages in the tidyverse have been super helpful to me for these tasks. I highly recommend that you write functions for your data cleaning/data processing scripts. [CROSS REF] Before you dig into the computing, though, two more important questions are: Does the PI know what data you have? It is quite possible that the PI was not directly involved in data collection. When the PI does not know what data you have, there is room for miscommunication - for example, the names of the variables in the data may not align with what the terminology that the PI is using. You may consider sending the PI a follow up email that describes the data you have (numbers of rows and columns, or a mock ‘Table 1’) and ask something like, “I want to confirm that I am looking at the right information as I begin to analyze your data. Is this [the description you’ve given] aligned with your expectations?” Does the data contain what you need to answer the PI’s research question? Related to the question above, if the PI is not familiar with the details of the data, it is possible that the data to which you have access is not adequate for addressing the research question. Again, describe the data you have and ask something like, “here is the data to which I have access; with my current understanding of your research question, I think you intend to analyze … Is my understanding correct? If so, some additional information is needed.” 5.2.2 The data accidentally contain HIPPA protected information This is one of those things that needs to be addressed early. Suppose that in your first exploration of a data set, you find that there is HIPPA protected (identifiable) data. As soon as you realize you have this, send an email to the person who shared the data with you and CC your GRA supervisor. Explain exactly what you have access to; say something like, “When I began to examine these data, I noticed that ___ information is included. This does not look like something to which I need access in order to address the research question. Please advise me on what needs to be done to de-identify these data?” 5.2.3 The PI is insistent on presenting results in a way that I believe is sub-optimal This is a tricky one – talk to your supervisor about this problem and ask for advice. It may be that there is a happy medium; for example, if the PI is insistent on using p-values, it may be possible for you to convince them to present confidence intervals or some measure of effect size to the results as well. Also, encourage your PI to name the limitation of the analysis choices you’ve made. For example, if you have done a bunch of multiple tests and have not corrected for multiple comparisons, you should mention that explicitly in the methods section of your work. 5.2.4 I realized I made a mistake in my code! As soon as you’ve realized you made a mistake, sit down and take a minute to reconstruct when you made the mistake. Write down: When you realized you made the mistake Whose work will be impacted by this mistake Once you have these things, consider your answer to (2). If the only people impacted by your mistake are other statisticians on your team, then email those people directly and explain what happened and what you are doing to make it right. If collaborators’ (e.g., clinicians or administrators) work is impacted by your mistake, email your RA supervisor first and explain what happened. As your supervisor to help you craft an email to the impacted individuals. 5.2.5 Collaborating with other students/trainees If you are collaborating with other students/residents/post-docs/trainees, I recommend that you CC their advisor(s) on all important communications (sharing results, asking clarifying questions, etc.). 5.2.6 Handling inappropriate/rude emails from a faculty member If you find yourself in the unpleasant situation where a faculty member sends an email that is rude, adversarial, or otherwise inappropriate (e.g., an investigator demands that you analyze the data according to their preferences/assumptions, even to the point of going against best practices…), I recommend that you do not respond. Instead, forward the email in question to your PI or other trusted senior faculty member and simply ask something like, ‘just want you to know I received this today – would you please help me handle this?’. In my experience as a student, I’d say you’re better off having a senior faculty member advocate for you than to try and advocate for yourself. 5.3 Maintaining a CV A curriculum vitae (CV) is not something you do once. It is something that requires constant maintenance. The tool I’ve found helpful for both 1) maintaining a CV that both looks professional and 2) is simple to update is the vitae package. The package site has a detailed README file with links to videos on how to set this up. I try to update my CV each time another publication is released. 5.4 Responding to reviewers One more aspect of professionalism that is a part of many research jobs is publishing in academic journals. When you submit a manuscript for publication, the draft you submit is given to peer-reviewers. These reviewers offer anonymous feedback to critique your work. Knowing how to respond to these reviewers is an integral part of the writing process. My research supervisor taught me to use the point-to-point method for responding to reviewers. Templates for point-to-point response are available here and here — check out these templates to get an idea of how to write your responses. "],["your-computing-setup.html", "Chapter 6 Your computing setup 6.1 Setting up R and RStudio (now Posit) 6.2 Setting up your terminal (i.e., the command line) 6.3 A few tips to get started 6.4 Getting started with Git 6.5 Using high performance computing clusters 6.6 Advanced R and some Julia", " Chapter 6 Your computing setup Your computing setup is an essential part of working as a biostats GRA. It is like organizing a toolbox - you have to choose the tools to work with, invest in those tools, decide how to organize/store them, and then (of course) actually work with them. Developing a ‘toolbox’ for quantitative work can have a lot of overhead – a steep learning curve – because systems for working in a computational/quantitative space are highly customizable. There are lots of ways to do things – and in may cases, there are multiple ways to do something well. The sheer number of options can make it hard to know where to start. So, the objective of this chapter is to offer a place to begin. For each of the components of my current toolbox, I am sharing one way to begin. My goal is to help you get started, trusting that you will gradually customize your setup to best suit your needs. I am writing as if I was writing to who I was 5 years ago – a total novice. If that’s not you, feel free to skip around – the subheadings in this chapter are labeled so that you can grab and go based on what you need from this chapter. 6.1 Setting up R and RStudio (now Posit) 6.1.1 Download and install R The tools I use the most are R/RStudio - in addition doing statistical analysis, I also use these tools to write documents (like this book!) and create graphics for publications. To get started with RStudio (now called Posit), you first need to install R. R is a programming language, meaning it provides a way to talk to your computer. R is specifically designed for statistics. Another great feature of R is that it is free – anyone can use it. In order for your computer to understand R, you need to download it and install it on your computer. This is your computer’s way of ‘learning’ a new language. Once you have downloaded R from the link above, you will have a file on your computer that you need to ‘unpack’ – click on what you’ve downloaded and follow the prompts to get R installed. 6.1.2 Download and install RStudio After your computer is ready to speak R, you need to have a way to talk to your computer. Just like when talking to a person, you need to both speak their language and have a way to communicate with them. We talk to each other in a number of ways, like using phones and messaging apps – in an analogous way, there are multiple avenues for ‘talking’ to your computer. One wayo talk R with your computer is to use RStudio. RStudio is an application (an ‘app’) that will let you interact with your computer in ways that make you more productive. Follow the link above to install RStudio for your computer – be sure to click on the download option that matches the kind of operating system your computer has (e.g., Mac OSX, Windows, Linux). Again, you need to install what you download – click on the file that shows up in your downloads folder, and follow the prompts to install RStudio. If you’d rather watch a video on how to install R and RStudio, check out this 15 minute video on YouTube. 6.1.3 Customize RStudio Once you have RStudio installed, you will see that you have a ‘Tools’ option at the top of your screen. Follow this menu to Tools &gt; Global Options. This will give you a pane that offers lots of settings. One cool thing to check out is the theme, meaning the color scheme/appearance of your terminal. You can choose a custom font or color palette in the ‘Appearances’ menu. I always use a dark mode theme (Tomorrow night is the theme I am using these days; Dracula is cool too). You will see that in your default RStudio viewer, you have 4 panes: one is the console (probably bottom left); code runs here, but nothing is saved here – it is like a place for ‘scratch work’. To save your work in a file, you need to open it in File &gt; Open file (this will probably open in the top left). Third, you will have a pane that shows your files (like a ‘Finder’ window on Mac, or a ‘Files’ window on Windows) - this pane is usually at the bottom right. At the top right, you will see a pane with a bar at the top listing options like ‘Environment’, ‘History’, etc. R is an object-oriented programming language (you can get really deep into thinking about this) – for our purposes now, just know that in R, the objects you create will show up in this ‘Environment’ pane. 6.1.4 Setting up your R library Using R requires packages. Most packages that you use will come from one of three places: CRAN, Bioconductor, or someone’s GitHub repository. To download and use a package from CRAN, use install.packages(&quot;package_name&quot;) # only need to do this once library(&quot;package_name&quot;) # this is what you would do each time To download a package from Bioconductor, use install.packages(&quot;BiocManager&quot;) BiocManager::install(c(&quot;package_name&quot;)) library(&quot;package_name&quot;) To download a package from a GitHub repository, use install.packages(&quot;devtools&quot;) devtools::install_github(&quot;user/repo&quot;) When you download a package, the package is saved in location that is specified as your library path. If you want to know where that is, type .libPaths() ## [1] &quot;/Users/tabithapeter/Library/R/x86_64/4.4/library&quot; ## [2] &quot;/Library/Frameworks/R.framework/Versions/4.4-x86_64/Resources/library&quot; 6.1.5 Tips: things you should never do in R/RStudio In the Environment pane, there is an icon to ‘save workspace as…’ - you should never save your R environment and/or your R workspace. This is bad practice for a number of reasons, including that you do not have control of what is being saved. Better alternative: save only the object(s) you need using saveRDS(). You can always re-access these later with readRDS(). Going back to the comment on file paths in the organization chapter, there is a function in R called setwd() where you can tell the computer where (what folder) to point. When writing a script, the first line of your script should never be setwd(\"a/directory/that/only/I/have) – you want your code to be portable, so that other people can run it (and so that you can run it even after you have reorganized your folders!). Better alternative: use relative file paths, like the structure provided in the super handy here R package. 6.1.6 Cool keyboard shortcuts in R/RStudio to make a chunk of code align (e.g., to fix the indentation): highlight the chunk and then CNTRL + I (Windows), Command + I (OSX) to create a new R script: CNTRL + Shift + N or Command + Shift + N to see all available keyboard shortcuts: ALT/Option + Shift + K 6.2 Setting up your terminal (i.e., the command line) There are two ways to interact with your computer: via ‘point and click’ interfaces (e.g., File Explorer on Windows, Finder on macOS) and via the command line. The command line is much more efficient for many computational tasks – I encourage anyone working in biostatistics to begin learning to use the command line for creating/moving/manipulating files, as this will be good preparation for doing more complicated work (e.g., writing your own R packages and so on). 6.2.1 Mac On a Mac, you can open the command line by searching for the ‘Terminal’ app (this is installed on every Mac by default). You have a lot of choices in addition to the apps that are on your computer by default. I use the app iTerm2, and I customized the appearance of my terminal window with Oh My ZSH framework. 6.2.2 Linux (Ubuntu, Debian, etc.) If you are using an Ubuntu system, your command line app is also ‘Terminal’. In Linux systems, you are probably running bash, and the Oh My BASH framework can help you customize your terminal. 6.2.3 Windows If you are on Windows, you will probably want to consider installing Windows Subsystem for Linux (WSL). The Windows command line too is called ‘Command Prompt’, but this is not compatible with most applications outside the Windows/Office 365 suite. 6.3 A few tips to get started As a first step in learning to work with the command line, try to find your files – in the video below, I show how I do this with symbolic links (‘symlinks’). More details on working with the command line are explained in the online course called “The missing semester of your computer science (CS) education.” This free online course was compiled by people at MIT. I have found this to be a really helpful place to begin. 6.3.1 Resources for learning the command line ARStechnica: command line wizardry, part I ARStechnica: command line wizardry, part II Linux Command line – official tutorial that starts from the very beginning Quick-start guide to the VIM text editor – VIM is a popular choice for text editing (other kinds of text editors are TextEdit (ships with Mac), NotePad/NotePad ++ (Windows)) 6.4 Getting started with Git Git is a free and open source command-line tool for version control. What this means is that Git allows you to avoid the problems that arise when you try to work with multiple copies of code for a project. Have you ever had a folder with files like this: analysis1.R, 04-05-2023_analysis.R, old_analysis.R, final_version.R, and final_final_version.R? This way of working is not only inefficient, but also inhibits collaboration and makes your work harder to reproduce. None of that is good for science. So, Git offers a way to manage versions, so that you can keep track of the current version of your code and have access to looking back at older versions. There are a lot of online tutorials to get you started with Git – just Google ‘git tutorial for beginners’ and several free options will show up. Again, the missing semester of your CS education course has a whole section on learning version control – highly recommend. Here is a brief overview of a few major vocab words you need to know to use Git (in the order in which you will probably encounter them): repository (‘repo’) (noun): The directory (a.k.a., the folder) that holds all the files for a project local versus remote (adjectives): These terms describe the location of a repo. A local repo exists only on one computer - for instance, a project that I have created on my laptop is a local repo. A remote repo is hosted online (probably on GitHub). Sort of like keeping files in OneDrive or GoogleDrive, remote repositories make it possible for multiple people to access a project from any computer. clone (verb): The action of making a copy of a repo. Example: “I will clone Person A’s remote repo onto my laptop.” The command line code for this is git clone &lt;repo&gt; pull (verb): The action of incorporating all of the changes from a remote repo into a local repo. Example: “My local copy of Repo A is out of sync with the master copy, since Person B made some more changes to our code yesterday. I need to pull those changes from our remote repo into my local repo.” Pulling is done with git pull. stage (verb): The action of preparing changes for a commit. This is like looking at your scratch work and deciding which of your ideas you want to keep. This is done with git add &lt;edited files to keep&gt;. commit (noun or verb): A commit (the noun) refers to a documented change to one or more files in a project. To make a commit (verb) is the action of saving a change. In broad, general terms, Git keeps a timeline of all the changes in a project. Once something is committed in Git, the changes that were part of that commit are permanently saved in the project timeline. To make a commit, use git commit -m \"a message describing the changes made\". push (verb): The action of moving commits you made in your local copy of the repo to the remote copy of the repo. Example: Me and my colleague Y are working on project A together. The master copy of project A is in our remote repo; me and Y have each cloned this repo, so we have local copies on our respective laptops. I have committed some changes in the files on my local copy, so now I need to push my commits to the remote repo. After I push, Y will be able to see what I did.” branch (noun): When working on a more complex project, there arises a need to keep two versions of the project: a ‘master’ version that has everything you want to keep for sure, and a ‘development’ version where you are debugging/troubleshooting/playing with new ideas. Having multiple branches in your repo allows you to achieve having multiple versions of a project as I’ve described. The commands that go along with branching are usually git branch and git checkout. 6.4.1 Resources for learning Git Quick-start: setting up Git Full book on Git - well divided into sections, so you can skip around to the chapters most relevant to what you need 6.5 Using high performance computing clusters In many contemporary applications, the computational work for data analysis needs to be done in a high performance computing cluster. At the University of Iowa, our high performance computing cluster is called Argon. One resources I have found super helpful in working with high performance computing clusters is the online tutorial written by Profs. Patrick Breheny and Grant Brown. This tutorial outlines how to use the UI Argon cluster. Much of what is here would generalize to other HPC systems as well. 6.5.1 Interactive sessions v. submitting jobs There are two ways to interact with a high performance computing cluster: an interactive session and a job submission. An interactive session involves you logging into the computer and telling it what to do one step at a time, whereas a job submission means you give the computer a whole set of instructions at once. In an interactive session, you stay logged in and watch the screen for results as they come in. In a job submission, you send you instructions (via a script) to the computer and then you are free to log out – the job will run until it either hits and error or finishes the job, and it will notify you in either case (for Argon, you get an email when your job is finished running). From here, you can see that jobs which you expect to take a while should be done via job submission. 6.5.2 Writing your first bash script For submitting jobs to a computing cluster, you will need to write a script – the set of instructions for the computer. Here is a tutorial for how to write a simple bash script – this is a great place to start if you are new to script writing. 6.5.3 Conda environments, module configurations, and containers This section will probably be most helpful for dissertation students or those working on advanced projects. If that’s not you yet, I’d encourage you to skip this for now. Conda, modules, and containers are all subjects where you could do a deep dive – here’s a few brief notes. Main point: When it comes to writing programs for data analysis, you will need to have a ‘setup’ of software on which your program depends. The software on which your work depends are called dependencies, and these dependencies have versions. A programmer needs to have a way to create a system of all the dependencies that the code needs, using all the right versions. This kind of system can be challenging to orchestrate. Conda, module configurations, and containers all offer solutions to these challenges. This issue of versions/dependencies comes up a lot when working with Python. Example: to use the LDSC command line tool for genetic correlation analysis, you need Python version 2.7 – but Python 3.10 is the most updated release of Python. In such a scenario, you need to tell your computer which version of Python to use. Moreover, you want to create a ‘setup’ for working with a tool like LDSC, and then every time you need to use this tool, you tell you computer: “load this special configuration of software” and it ‘remembers’ what configuration that is. Saving a configuration in this way can be done with either conda environments or module configurations. Conda is a package management system that you can download for your computer and then use the command conda to create custom environments. Alternatively, some computer systems (like the UI Argon HPC) have pre-installed capability to configure custom modules. One thing that gave me issues early on in my dissertation work is that I was trying to create a conda environment inside of my module configuration. Don’t mix and match the two approaches – choose to either create environments or configure modules, and stick with you choice. Your choice here will depend in large part to the type of computer system you are working with, e.g., on UI Argon, it is much simpler to configure modules because that is already pre-installed and set to the default. Checkout the program files and modules section of the HPC tutorial for an example of this syntax. Yet a third solution to this issue of dependencies and versions is containerization. This is what I used in my dissertation – my dissertation required the installation of several C++/R packages, my own R package in its development version, and R &gt;= 4.4.1. Trying to set all of that up with a module configuration proved to be quite challenging – among other issues, the modules available did not have the most recent version of R. As a solution, I created a container with podman (a Linux package), converted this podman container into an apptainer, and then copied the image file of my apptainer onto the high-performance computing platform. The best 5 minute beginner-level YouTube video I’ve found explaning containerization is here. Instructions for how to implement the podman -&gt; apptainer workflow are available here (courtesy of Grant Brown). 6.6 Advanced R and some Julia Just for reference, here are some links I have found helpful for learning more advanced R and some Julia – special thanks again to Grant Brown for touching on these ideas in his course on Advanced Computing: Advanced R, 2nd edition – again, well-divided into sections, so its simple to navigate Efficient R programming – this is really great for people who are learning R with more of a math/stats background than a computing background. Regarding tips for writing better R code, there are some real gems here. Free course in Julia. "],["writing-reports.html", "Chapter 7 Writing reports 7.1 What makes a report ‘good’? 7.2 Outline of a report 7.3 Tools for writing reports", " Chapter 7 Writing reports 7.1 What makes a report ‘good’? The final product for a project is usually a report, rather than a script or a set of unformatted results. Once you have your statistical estimates, consider how you can craft the results into a story. Good research reports effectively communicate stories. Here are some general features of reports that tell stories: Good reports are reproducible: is it simple to reproduce your report, such as re-knitting a single R-markdown file? If it’s not easy to reproduce, this is usually a sign that something could be done better/more efficiently/more robustly. Good reports are easily navigated by audience: don’t send raw output to collaborators! Good reports tell the whole story: include the context, methods, results, and limitations of the study. Each of these components is important for telling the truth. Good reports use visuals: summarizes information in tables/graphs whenever possible. 7.2 Outline of a report As a place to start, try outlining your reports in the same way that many scientific journal articles are organized: Background: Give the context of the work. In the first paragraph, make a clear statement of the objective of the work. Example: “The objective of this project is to investigate how, if at all, ___ impacts ___.” Methods: Summarize the methods you used to analyze the data. Note the software you used, and the version of that software at the time of analysis. Also state any decisions that you made about how data were interpreted. Example: “We used a linear mixed model to test the effect of drug X on measurement A while accounting for the grouping structure among observations. We classified the grouping structures as , , and __. All analysis was done using R 4.4.1” If you are using publicly available data, state your data source - e.g., “The 2019 version of the __ dataset was downloaded from __ site.” Results: At the beginning of your results section, state the takeaways that are most important to your audience. In these statements, indicate the degree and direction of evidence. Then illustrate this with tables and graphs. Example: “We found mild evidence that drug X was associated an increase in measurement A, as shown in Figure 2.” Some phrases I have used in writing results sections: “The data suggest that …”, “The data show mild/moderate/strong evidence of …”, “Although we observed ___, the evidence of an association was weak/inconclusive.” Discussion: For the statistician, the main contributions towards the discussion are (1) naming the limitations of the data analysis and (b) offering directions for future work. Examples of how to name limitations: “Although we chose to use/implement __, this choice assumes that … An alternative approach could be…” “Due to __ factors, we chose to apply __ – a limitation of this approach is …” “We recommend readers to consider __ as part of interpreting these results.” “The evidence in this study may not generalize to __ population(s); further work should explore …” References: Be sure to cite the methods and software you used. Including citations will also help your collaborators as they incorporate your report into the larger work (e.g., the grant, the article, etc.) If you used publicly available data, add a citation for that source as well. 7.3 Tools for writing reports R packages to create tables: gtsummary - best overall; best for displaying regression model estimates; ‘prettiest’ output compareGroups - best bivariate testing table (shows ORs without custom formatting needed). arsenal - easiest to customize Resources to format reports: kable/kableExtra R packages tutorial on LaTeX tables in PDF tutorial on tables in HTML "],["giving-presentations.html", "Chapter 8 Giving presentations 8.1 Tips and ideas 8.2 Tools for giving presentations", " Chapter 8 Giving presentations A presentation is effective when everyone in the audience learns something. With that in mind, craft your presentations with the audience in mind. If you’re using PowerPoint/Beamer/some other slide deck tool, use more pictures than words. As Dr. Melissa Marshall says, “Bullets kill” – meaning too many bullet points will kill your presentation. 8.1 Tips and ideas Use the title space on a slide for a short statement of the point you are making. Use the content space to add an image with a graphic or table to illustrate your point. Write the comments you want to make as bullet points in a sheet of speaker notes, not on the slides! You can even give the audience a copy of your speaker notes if you want them to follow along. Consider making your slides publicly available and linking them with a QR code to your opening slide. If you are including an equation or derivation, use colored text to mark the term or symbol that you want to highlight. 8.2 Tools for giving presentations Melissa Marshall’s resources at Present Your Science. There’s a lot here (including a TED talk) on how to use slideshows to effectively communicate to diverse audiences. 10/10, highly recommend. Quarto presentations - unlike Rmd files, you can knit to PowerPoint in Quarto. Also, Quarto is great for presentations where you need to show blocks of code. University of Iowa Beamer slides template. This template is UI specific, and the color schemes stay within the guidelines of the UI brand manual. "],["the-basics-t-tests-anova-and-linear-regression.html", "Chapter 9 The basics: t-tests, ANOVA, and linear regression 9.1 t-tests &amp; ANOVA 9.2 Linear regression", " Chapter 9 The basics: t-tests, ANOVA, and linear regression The most basic statistical analyses for a GRA to use are t-tests, analysis of variance, and linear regression. Here are some tips and references for getting started and creating well-formatted output: 9.1 t-tests &amp; ANOVA The best R-package I have used for doing t-tests and ANOVA is gtsummary, a package that makes beautiful tables for summarizing data. Here is an example of a t-test with gtsummary: library(gtsummary) # lets use the ToothGrowth data str(ToothGrowth) ## &#39;data.frame&#39;: 60 obs. of 3 variables: ## $ len : num 4.2 11.5 7.3 5.8 6.4 10 11.2 11.2 5.2 7 ... ## $ supp: Factor w/ 2 levels &quot;OJ&quot;,&quot;VC&quot;: 2 2 2 2 2 2 2 2 2 2 ... ## $ dose: num 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 ... # Note: I am assuming here that you have checked the appropriate diagnostics ( # e.g., check residuals for normality, check for outliers, check variances in both groups, etc.) tbl_summary(ToothGrowth, # data set by = &quot;supp&quot;, # factor/grouping variable include = &quot;len&quot;, # numeric outcome label = list(&quot;len&quot; ~ &quot;Length&quot;), # make a readable label # t-test is a test of means, so let&#39;s summarize data with mean (sd) form statistic = list(all_continuous() ~ &quot;{mean} ({sd})&quot;), # choose reasonable number of digits to print digits = list(everything() ~ 2)) |&gt; # indicate that you want a t.test add_p(test = list(all_continuous() ~ &quot;t.test&quot;)) |&gt; # format labels bold_labels() |&gt; # remove default &#39;Characteristic&#39; header modify_header(label = &quot;&quot;) #lhkaxoiexw table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #lhkaxoiexw thead, #lhkaxoiexw tbody, #lhkaxoiexw tfoot, #lhkaxoiexw tr, #lhkaxoiexw td, #lhkaxoiexw th { border-style: none; } #lhkaxoiexw p { margin: 0; padding: 0; } #lhkaxoiexw .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #lhkaxoiexw .gt_caption { padding-top: 4px; padding-bottom: 4px; } #lhkaxoiexw .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #lhkaxoiexw .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #lhkaxoiexw .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #lhkaxoiexw .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #lhkaxoiexw .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #lhkaxoiexw .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #lhkaxoiexw .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #lhkaxoiexw .gt_column_spanner_outer:first-child { padding-left: 0; } #lhkaxoiexw .gt_column_spanner_outer:last-child { padding-right: 0; } #lhkaxoiexw .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #lhkaxoiexw .gt_spanner_row { border-bottom-style: hidden; } #lhkaxoiexw .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #lhkaxoiexw .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #lhkaxoiexw .gt_from_md > :first-child { margin-top: 0; } #lhkaxoiexw .gt_from_md > :last-child { margin-bottom: 0; } #lhkaxoiexw .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #lhkaxoiexw .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #lhkaxoiexw .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #lhkaxoiexw .gt_row_group_first td { border-top-width: 2px; } #lhkaxoiexw .gt_row_group_first th { border-top-width: 2px; } #lhkaxoiexw .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #lhkaxoiexw .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #lhkaxoiexw .gt_first_summary_row.thick { border-top-width: 2px; } #lhkaxoiexw .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #lhkaxoiexw .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #lhkaxoiexw .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #lhkaxoiexw .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #lhkaxoiexw .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #lhkaxoiexw .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #lhkaxoiexw .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #lhkaxoiexw .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #lhkaxoiexw .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #lhkaxoiexw .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #lhkaxoiexw .gt_left { text-align: left; } #lhkaxoiexw .gt_center { text-align: center; } #lhkaxoiexw .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #lhkaxoiexw .gt_font_normal { font-weight: normal; } #lhkaxoiexw .gt_font_bold { font-weight: bold; } #lhkaxoiexw .gt_font_italic { font-style: italic; } #lhkaxoiexw .gt_super { font-size: 65%; } #lhkaxoiexw .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #lhkaxoiexw .gt_asterisk { font-size: 100%; vertical-align: 0; } #lhkaxoiexw .gt_indent_1 { text-indent: 5px; } #lhkaxoiexw .gt_indent_2 { text-indent: 10px; } #lhkaxoiexw .gt_indent_3 { text-indent: 15px; } #lhkaxoiexw .gt_indent_4 { text-indent: 20px; } #lhkaxoiexw .gt_indent_5 { text-indent: 25px; } #lhkaxoiexw .katex-display { display: inline-flex !important; margin-bottom: 0.75em !important; } #lhkaxoiexw div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after { height: 0px !important; } OJ N = 301 VC N = 301 p-value2 Length 20.66 (6.61) 16.96 (8.27) 0.061 1 Mean (SD) 2 Welch Two Sample t-test For ANOVA, we could do this: tbl_summary(ToothGrowth, by = dose, # factor/grouping variable is now &#39;dose&#39; include = &quot;len&quot;, label = list(&quot;len&quot; ~ &quot;Length&quot;), statistic = list(all_continuous() ~ &quot;{mean} ({sd})&quot;), digits = list(everything() ~ 2)) |&gt; # indicate that you want a one-way ANOVA test here, not assuming equal variances add_p(test = list(all_continuous() ~ &quot;oneway.test&quot;)) |&gt; bold_labels() |&gt; modify_header(label = &quot;&quot;) #cccoexaaoo table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #cccoexaaoo thead, #cccoexaaoo tbody, #cccoexaaoo tfoot, #cccoexaaoo tr, #cccoexaaoo td, #cccoexaaoo th { border-style: none; } #cccoexaaoo p { margin: 0; padding: 0; } #cccoexaaoo .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #cccoexaaoo .gt_caption { padding-top: 4px; padding-bottom: 4px; } #cccoexaaoo .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #cccoexaaoo .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #cccoexaaoo .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #cccoexaaoo .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #cccoexaaoo .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #cccoexaaoo .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #cccoexaaoo .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #cccoexaaoo .gt_column_spanner_outer:first-child { padding-left: 0; } #cccoexaaoo .gt_column_spanner_outer:last-child { padding-right: 0; } #cccoexaaoo .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #cccoexaaoo .gt_spanner_row { border-bottom-style: hidden; } #cccoexaaoo .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #cccoexaaoo .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #cccoexaaoo .gt_from_md > :first-child { margin-top: 0; } #cccoexaaoo .gt_from_md > :last-child { margin-bottom: 0; } #cccoexaaoo .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #cccoexaaoo .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #cccoexaaoo .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #cccoexaaoo .gt_row_group_first td { border-top-width: 2px; } #cccoexaaoo .gt_row_group_first th { border-top-width: 2px; } #cccoexaaoo .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #cccoexaaoo .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #cccoexaaoo .gt_first_summary_row.thick { border-top-width: 2px; } #cccoexaaoo .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #cccoexaaoo .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #cccoexaaoo .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #cccoexaaoo .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #cccoexaaoo .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #cccoexaaoo .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #cccoexaaoo .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #cccoexaaoo .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #cccoexaaoo .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #cccoexaaoo .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #cccoexaaoo .gt_left { text-align: left; } #cccoexaaoo .gt_center { text-align: center; } #cccoexaaoo .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #cccoexaaoo .gt_font_normal { font-weight: normal; } #cccoexaaoo .gt_font_bold { font-weight: bold; } #cccoexaaoo .gt_font_italic { font-style: italic; } #cccoexaaoo .gt_super { font-size: 65%; } #cccoexaaoo .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #cccoexaaoo .gt_asterisk { font-size: 100%; vertical-align: 0; } #cccoexaaoo .gt_indent_1 { text-indent: 5px; } #cccoexaaoo .gt_indent_2 { text-indent: 10px; } #cccoexaaoo .gt_indent_3 { text-indent: 15px; } #cccoexaaoo .gt_indent_4 { text-indent: 20px; } #cccoexaaoo .gt_indent_5 { text-indent: 25px; } #cccoexaaoo .katex-display { display: inline-flex !important; margin-bottom: 0.75em !important; } #cccoexaaoo div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after { height: 0px !important; } 0.5 N = 201 1 N = 201 2 N = 201 p-value2 Length 10.61 (4.50) 19.74 (4.42) 26.10 (3.77) 1 Mean (SD) 2 One-way analysis of means (not assuming equal variances) 9.2 Linear regression gtsummary will also create summary tables for linear regression, like so: # use the &#39;iris&#39; data this time str(iris) ## &#39;data.frame&#39;: 150 obs. of 5 variables: ## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... my_model &lt;- lm(Petal.Length ~ Species + Sepal.Length, data = iris) # again, I am assuming you have checked the appropriate linear model diagnostics tbl_regression(my_model) |&gt; modify_header(label = &quot;**Feature**&quot;, estimate = &quot;**Estimate**&quot;) |&gt; bold_labels() #nfksswutij table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #nfksswutij thead, #nfksswutij tbody, #nfksswutij tfoot, #nfksswutij tr, #nfksswutij td, #nfksswutij th { border-style: none; } #nfksswutij p { margin: 0; padding: 0; } #nfksswutij .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #nfksswutij .gt_caption { padding-top: 4px; padding-bottom: 4px; } #nfksswutij .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #nfksswutij .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #nfksswutij .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #nfksswutij .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #nfksswutij .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #nfksswutij .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #nfksswutij .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #nfksswutij .gt_column_spanner_outer:first-child { padding-left: 0; } #nfksswutij .gt_column_spanner_outer:last-child { padding-right: 0; } #nfksswutij .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #nfksswutij .gt_spanner_row { border-bottom-style: hidden; } #nfksswutij .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #nfksswutij .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #nfksswutij .gt_from_md > :first-child { margin-top: 0; } #nfksswutij .gt_from_md > :last-child { margin-bottom: 0; } #nfksswutij .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #nfksswutij .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #nfksswutij .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #nfksswutij .gt_row_group_first td { border-top-width: 2px; } #nfksswutij .gt_row_group_first th { border-top-width: 2px; } #nfksswutij .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #nfksswutij .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #nfksswutij .gt_first_summary_row.thick { border-top-width: 2px; } #nfksswutij .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #nfksswutij .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #nfksswutij .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #nfksswutij .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #nfksswutij .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #nfksswutij .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #nfksswutij .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #nfksswutij .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #nfksswutij .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #nfksswutij .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #nfksswutij .gt_left { text-align: left; } #nfksswutij .gt_center { text-align: center; } #nfksswutij .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #nfksswutij .gt_font_normal { font-weight: normal; } #nfksswutij .gt_font_bold { font-weight: bold; } #nfksswutij .gt_font_italic { font-style: italic; } #nfksswutij .gt_super { font-size: 65%; } #nfksswutij .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #nfksswutij .gt_asterisk { font-size: 100%; vertical-align: 0; } #nfksswutij .gt_indent_1 { text-indent: 5px; } #nfksswutij .gt_indent_2 { text-indent: 10px; } #nfksswutij .gt_indent_3 { text-indent: 15px; } #nfksswutij .gt_indent_4 { text-indent: 20px; } #nfksswutij .gt_indent_5 { text-indent: 25px; } #nfksswutij .katex-display { display: inline-flex !important; margin-bottom: 0.75em !important; } #nfksswutij div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after { height: 0px !important; } Feature Estimate 95% CI1 p-value Species     setosa — —     versicolor 2.2 2.1, 2.3     virginica 3.1 2.9, 3.3 Sepal.Length 0.63 0.54, 0.72 1 CI = Confidence Interval For logistic regression, you will need to do some futher customization of the output to get the odds ratio estimates to appear in the table - take a look at this help documentation for examples. For more on diagnostics/checking assumptions: this article on STHDA gives some examples of checking assumptions for linear regression in R. "],["power-and-sample-size-calculations.html", "Chapter 10 Power and sample size calculations", " Chapter 10 Power and sample size calculations Power and sample size calculations are a common request for a GRA. In order to estimate the power or calculate the necessary sample size, you will need some measure of effect size. Often, the PI may not have an effect size in mind – in this case, offer some example scenarios and gauge the PI’s reaction. Examples: “If you saw that a subject being treated in group B had a 2 mm increase in the outcome, would you be impressed? Would that be a ‘big’ or notable change?” “How much of an impact would you need to see in order to catch you attention in an abstract? A 50% increase? Double the outcome?” Your calculations for power/sample size could be done several ways in R: the pwr and pwr2 packages can be a good place to start. SAS offers the PROC POWER procedure for doing power and sample size calculations. I have often used both R and SAS functions for the same calculation and compared the results. Typically, SAS has much more in-depth documentation – if you are wondering about the theoretical details for a calculation, SAS documentation is a helpful resource. "],["survival-time-to-event-analysis.html", "Chapter 11 Survival (time-to-event) analysis 11.1 Quick examples 11.2 R code tips 11.3 References", " Chapter 11 Survival (time-to-event) analysis Survival analysis (also called ‘time-to-event analysis’) is one of the problem-solving settings that separates biostatistics from pure statistics. Survival analysis research questions ask, “How long until (some event) happens?”. This is a messy question, especially in biomedical research contexts where the investigators do not observe what happens to every observational unit (e.g, every patient) in the study. A patient may come to the clinic once, receive treatment, and then never come back to the clinic again. Whatever outcome the investigators wanted to observe remains unknown for that patient – we would say the outcome for such a patient is censored. The most-used methods in survival analysis are the log-rank test and the Cox proportional hazards model. The log-rank test is a conceptual analog to a Cochran-Mantel-Haenzel test in categorical data analysis. When working with a survival outcome and a single categorical predictor, the log-rank test can be used to test the null hypothesis: “there is no difference in survival between the groups being compared.” The Cox proportional hazards model is a multivariate regression approach in which the exponentiated coefficients are the hazard ratios. 11.1 Quick examples Here are a few brief survival analysis scenarios: Clinical trials: patients battling a chronic condition are randomized to either new drug B or the standard of care drug A. Patients have follow-up visits once per month for 1 year to monitor the time until their symptoms flare up again (e.g., time to relapse or time to recurrence). Dentistry: electronic dental records are used to assess the time until re-intervention for crown margin repairs (CMRs). CMRs are compared to assess which materials last longer: glass ionomer, resin-modified glass ionomer, resin-based composite, and amalgam. Industry/manufacturing: Suppose there are four machines on a factor floor, two from brand A and two from brand B. The time until next malfunction could be used to compare the two brands of machines. 11.2 R code tips Packages to know about: survival: a must-have for survival analysis ggsurvfit: more options for for graphics contsurvplot: great for visualizing effects of continuous covariates 11.3 References Emily Zaboor’s survival analysis tutorial in R. Good quick-reference for code and plots. Patrick Breheny’s publically available course notes for survival analysis. Lots of examples here, goes in depth in the theory. "],["survey-data-analysis.html", "Chapter 12 Survey data analysis", " Chapter 12 Survey data analysis The survey R package is the classic tool for this type of analysis. This package has extensive documentation. The author of the package has posted publicly available notes from a JSM workshop that includes more theoretical foundations. The srvyr R package offers tidyverse syntax of the survey package functions A more extensive list of survey analysis tools is compiled here. "],["longitudinal-data-analysis.html", "Chapter 13 Longitudinal data analysis 13.1 Tools for longitudinal data analysis", " Chapter 13 Longitudinal data analysis 13.1 Tools for longitudinal data analysis lme4 R package - fits all your basic linear mixed models nlme R package - offers functionality for nonlinear mixed effect models TODO: add SAS procedures/documentation TODO: see if I can get permission to post some past analysis code as an example "],["microbiome-data-analysis.html", "Chapter 14 Microbiome data analysis 14.1 Tools for working with microbiome data", " Chapter 14 Microbiome data analysis Microbiome data analysis requires working with two separate subtypes of data: the taxonomic data and the sample (meta)data. Taxonomic data is hierarchical, meaning that the data are structured in tiers. These tiers are typically the Operational Taxonomic Units (OTUs). The sample data is the data describing the observations (people or subjects) in the data, and often includes demographic/clinical features. 14.1 Tools for working with microbiome data metacoder is an R package that is built on previous packages vegan and phyloseq. All of these links include tutorials for working with taxonomic data. "],["genome-wide-association-gwas-data.html", "Chapter 15 Genome-wide association (GWAS) data 15.1 Principal component analysis (PCA) 15.2 R packages 15.3 Bioconductor packages 15.4 Command-line tools", " Chapter 15 Genome-wide association (GWAS) data New tools for genetic/genomic data analysis are being created at a mind-boggling rate. It seems like a new paper in this area comes out each week – which makes it a challenge to summarize the tools available for working in this area. With this in mind, consider the set of tools and tips provided here as select suggestions from my own experience rather than an exhaustive list. A tutorial for GWAS in R is available here. 15.1 Principal component analysis (PCA) One concept that comes up often in GWAS data is principal components – this CrossValidated post is the best explanation I have read on PCA. Another site that may be helpful is this one, which has examples of visualizing PCA in R. 15.2 R packages 15.2.1 for analyzing one genetic marker at a time bigsnpr analyses GWAS scale data, includes PCA, fitting lasso models, doing some quality control qqman creates Manhattan plots and QQ plots 15.2.2 for analyzing markers together in an additive model ncvreg fits nonconvex penalized linear mixed models in R plmmr does penalized linear mixed models in R 15.2.3 for summary-level GWAS data PLACO: this isn’t a ‘package’ per se, but this method for assessing pleiotropy between traits is implemented in R. 15.3 Bioconductor packages snpStats 15.4 Command-line tools PLINK is arguably the most established tool for managing and analyzing genetic/genomic data. Definitely worth learning if you are interested in working with this kind of data. This is probably the best tool to start learning if you are new to the field. LDSC is a tool for estimating heritability and genetic correlation from GWAS summary statistics. HEELS does heritability estimation with high-efficiency using LD and summary statistics. "],["geographic-gis-data-analysis.html", "Chapter 16 Geographic (GIS) data analysis", " Chapter 16 Geographic (GIS) data analysis One really useful way to illustrate data is through making maps. Here’s an example based on a real project I did in 2022 (data are available in the data/ subfolder of this repository). Suppose that a principal investigator (PI) wants to study access to care through teledentistry. The specific research question is something like, “in a population of patients treated at my dental clinic from January 2021 - May 2023, what were the patterns in the relationships between 1) the distance traveled to the clinic, 2) the mode of the intake exam (in-person or virtual), and 3) treatment completion within 6 months (yes or no). Suppose further that I (the analyst) have access to the county in which each person lives, in addition to the clinical information relevant to our research in the electronic dental records. Let’s start by loading all the libraries we’ll need: library(dplyr) # package for &#39;wrangling&#39; data library(sf) # package for analyzing GIS data library(ggplot2) # package for drawing plots/graphs library(viridis) # package for choosing good color palettes library(knitr) # package for making tables After loading libraries, the first thing I would do is look online to find publicly available data with Federal Information Processing Standard (FIPS) codes for Iowa at the county level. I will use the R package sf to handle GIS data, which often comes in .shp or GeoJSON formats. Data in these sorts of files have what we need to draw a map of Iowa with the counties demarcated on the map. # read in GeoJSO file ia &lt;- st_read(&quot;data/Iowa_County_Boundaries.geojson&quot;) ## Reading layer `IowaCounties&#39; from data source ## `/Users/tabithapeter/Desktop/ra_reference_manual/data/Iowa_County_Boundaries.geojson&#39; using driver `GeoJSON&#39; ## Simple feature collection with 99 features and 9 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: -96.63944 ymin: 40.37566 xmax: -90.1401 ymax: 43.50109 ## Geodetic CRS: WGS 84 # must create a &#39;geometry&#39; object ia_geom &lt;- st_geometry(ia) # Note: in &#39;ia&#39;, O&#39;Brien county is labeled as &#39;Obrien&#39;-- as is often the case, # special characters like apostraphes need special handling ia |&gt; dplyr::filter(substr(CountyName,1,1) == &quot;O&quot;) ## Simple feature collection with 2 features and 9 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: -95.86234 ymin: 42.90917 xmax: -95.38744 ymax: 43.50024 ## Geodetic CRS: WGS 84 ## OBJECTID PERIMETER DOMCountyID FIPS FIPS_INT CountyName StateAbbr SHAPE_Length SHAPE_Area ## 1 2 130929.6 72 19143 19143 Osceola IA 1.434543 0.1148673 ## 2 13 154085.1 71 19141 19141 Obrien IA 1.639165 0.1640720 ## geometry ## 1 MULTIPOLYGON (((-95.86089 4... ## 2 MULTIPOLYGON (((-95.86193 4... # This is important - we will need to adjust our data later on to make things match. # But first, let&#39;s create a test plot to make sure the map looks right. par(mar = c(0,0,1,0)) plot(ia[1], reset = FALSE) # reset = FALSE: we want to add to a plot with a legend This sample map is the correct shape – here, the 99 counties are colored according to their index (1-99). We want to make a map where the colors correspond to the number of patients representing each county. Supposing one has access to electronic dental records, the data for such a study may look like this: # read in CSV file that gives me county names key &lt;- read.csv(&quot;data/ia_counties.csv&quot;) |&gt; # narrow down to only IA (for sake of example) dplyr::filter(State == &quot;IA&quot;) |&gt; # address the issue with the special character in O&#39;Brien dplyr::mutate(NAME = dplyr::if_else(NAME == &quot;O&#39;Brien&quot;, &quot;Obrien&quot;, NAME)) # now simulate mock data for our example # note: TD = teledentistry set.seed(52242) td &lt;- data.frame( # creating data from 1000 pretend IDs id = 1:1000, # randomly choose a year for each ID year = sample(2021:2023, 1000, replace = TRUE), # randomly choose an outcome for each ID # (complete or incomplete, represented as 1 or 0) complete = sample(0:1, 1000, replace = TRUE), # randomly choose a county for each ID county = sample(key$NAME, 1000, replace = TRUE), # randomly choose a model for each ID mode = sample(c(&quot;virtual&quot;, &quot;in-person&quot;), 1000, replace = TRUE) ) # see what these data look like: head(td) |&gt; # note the use of the &#39;kable()&#39; function from the &#39;knitr&#39; package below: # this is another great tool for making tables, when you want to see a # glimpse of the data knitr::kable(caption = &quot;Simulated data from electronic dental records&quot;) Table 16.1: Simulated data from electronic dental records id year complete county mode 1 2021 0 Howard virtual 2 2021 1 Clay in-person 3 2021 0 Palo Alto virtual 4 2022 0 Buchanan virtual 5 2022 0 Obrien virtual 6 2023 1 Floyd virtual Now, I am ready to create a map that will communicate to my collaborators where our patients are driving from to receive their treatment. # determine how many patients in each county td_summarize &lt;- td |&gt; group_by(county) |&gt; summarise(N = n()) |&gt; ungroup() # add fips codes (from GeoJSON file) td_summarize &lt;- right_join(td_summarize, ia, by = c(&quot;county&quot; = &quot;CountyName&quot;)) # create sf object (for drawing a map) map &lt;- td_summarize |&gt; st_as_sf() # draw the map ggplot() + geom_sf(data = map, aes(fill = N)) + scale_fill_viridis() + labs(title = &quot;Map of IA Residents by County&quot;, fill = &quot;Number of \\npatients&quot;) + theme_bw() "]]
